\documentclass[a5paper]{article}
\usepackage[a5paper, top=17mm, bottom=17mm, left=17mm, right=17mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T2A,T1]{fontenc}
\usepackage[colorlinks,filecolor=blue,citecolor=green,unicode,pdftex]{hyperref}
\usepackage{cmap}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{color}
\usepackage{array}
\usepackage{hhline}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue, pdftitle=1, pdfauthor=, pdfsubject=, pdfkeywords=}
% \usepackage[pdftex]{graphicx}
\usepackage{graphicx}
% \usepackage{epigraph}
% Раскомментировать тем, у кого этот пакет есть. Шрифт станет заметно красивее.
%\usepackage{literat}
\usepackage{indentfirst}
\usepackage{multirow}

\sloppy
\pagestyle{plain}
%\pagestyle{empty}

\title{Применение жестов мышью в CASE-системах}

\author{М.С. Осечкина \and Т.А. Брыксин \and Ю.В. Литвинов}
\date{}
\begin{document}

\maketitle
\thispagestyle{empty}

\begin{quote}
\small\noindent
В данной работе рассматриваются подходы к распознаванию жестов мышью и применение их в CASE-системах. Приводится численное сравнение алгоритмов распознавания, не использующих предварительное обучение. Делаются выводы о применимости данного класса алгоритмов для повышения эффективности и удобства работы проектировщика, пользующегося CASE-системой.
\end{quote}

\section*{Введение}
Одной из особенностей разработки, управляемой моделями (model-driven development, MDD), является активное использование визуальных языков. Практически все действия, выполняемые в CASE-средствах или других используемых инструментах так или иначе сводятся к манипуляциям над элементами этих языков и связями между ними. 

Эффективность любого используемого инструмента определяется тем, насколько удобно и быстро он позволяет выполнять те операции, для которых этот инструмент предназначен. В процессе разработки моделей одними из наиболее часто выполняемых действий над объектами на диаграммах являются их создание и удаление.  В большинстве CASE-средств для того, чтобы создать нужный объект на диаграмме, необходимо найти его либо на панели инструментов, либо выбрать в меню, а затем указать место на диаграмме, где бы мы хотели этот элемент разместить. Также в большинстве инструментариев возможен вариант создания объектов «перетаскиванием» (drag and drop) их из палитры. То есть даже для такой базовой операции, как создание нового элемента, разработчику нужно совершить не только набор чисто механических действий, но еще и, скажем, вспомнить, на какой вкладке палитры или в каком меню находится нужный ему элемент, тем самым переключая контекст с продумывания иерархии создаваемых моделей на особенности использования выбранного инструмента. Нам кажется, что данную операцию можно и нужно автоматизировать, причем её нужно сделать максимально удобной для пользователей CASE-средств. 

В данной статье в качестве такого решения рассматривается подход, основанный на жестах мышью. Предлагается с каждым элементом ассоциировать определенный жест мышью, выполненный с каким-либо модификатором (скажем, с зажатой правой кнопкой мыши или клавишей Alt) и при выполнении этого жеста создавать в данном месте соответствующий объект. Например, если пользователь на диаграмме случаев использования UML рисует круг, у него создается случай использования (use case), если рисует актёра --- создаётся элемент ``актёр'' (actor).

Существует довольно много приложений, в которых использование жестов мыши уже нашло свое применение, например, браузер Opera\footnote{http://www.opera.com/}, некоторые игры. Некоторые из них (такие, как StrokeIt, gMote и др.) даже позволяют внедрить поддержку  жестов мышью в произвольные приложения. Более того, существуют и CASE-системы, использующие подобный подход, например, Visual Paradigm\footnote{http://www.visual-paradigm.com/product/vpuml/}. Но поддержка жестов мышью в таких программах ограничена тем, что набор жестов фиксирован, что недопустимо для расширяемых систем. В данной статье описывается опыт внедрения жестов мышью в приложение, в котором набор жестов неизвестен априори и может быть расширен.

В статье проводится анализ и сравнение существующих алгоритмов распознавания жестов мышью применительно к использованию в CASE-системах и предлагается алгоритм, позволяющий поддержать жесты мышью для элементов диаграмм в CASE-системе, в которой набор графических элементов может расширяться динамически. На основе данного алгоритма в среде QReal~\cite{qreal} была создана инфраструктура поддержки жестов. В статье описываются результаты апробации данного подхода на примере нескольких графических редакторов из состава QReal. 

\section{Обзор}

\subsection{Использование жестов мышью в других приложениях}

В последнее время разработкам нетрадиционных подходов к организации человеко-машинного взаимодействия уделяется довольно много внимания, и идея подавать команды программам с помощью жестов мыши уже нашла свое применение во многих приложениях. Так, например, в веб-браузер Opera встроена поддержка простейших жестов, вызывающих наиболее часто применяемые команды. К примеру, чтобы вернуться к предыдущей странице, можно нажать кнопку ``Back`` в панели браузера, а можно выполнить движение мышью влево при зажатой правой кнопке. Чтобы перейти к следующей странице (кнопка ``Forward``), нужно двигать мышь вправо, для обновления страницы (кнопка ``Reload'') -- вверх-вниз, чтобы открыть новую вкладку -- вниз. Ясно, что при таких абстрактных жестах от алгоритма распознавания не требуется большая точность -- достаточно просто разбить жест на направления и выделить 1-3 вектора наибольшей длины.

В некоторых компьютерных играх жесты позволяют указывать персонажам куда двигаться или заставляют их выполнять какие-то определенные действия. Набор жестов в известных нам приложениях такого рода статичен и не может быть изменён без модификации кода игры.

Также существуют специальные утилиты, с помощью которых можно ввести поддержку жестов мышью в любую программу~\cite{strokeIt, gMote, xstroke, flyGesture}. Их недостаток с точки зрения рассматриваемой задачи состоит в том, что добавляется лишь ограниченное число заранее определенных команд, таких, как сохранение, распечатка, копирование, вставка и т.п. В CASE-системах для полноценной поддержки создания элементов требуется на порядок больше различных жестов. И если в вышеперечисленных утилитах можно обойтись перебором всевозможных путей мыши, по которым вызывается та или иная команда, то в CASE-средстве перебирать придется слишком много вариантов. Ограничиться простейшими жестами (вверх, вниз, вправо, влево) невозможно, так как объектов слишком много и может возникнуть конфликт между двумя командами, у которых будет один и тот же жест. Возможным решением в таких случаях было бы по жесту предоставлять список команд, из которых пользователь может выбрать. Но если список будет слишком большим или будет вызываться при каждом жесте мышью, то смысл введения жестов пропадает, так как большинство инструментов уже предоставляет пользователю список объектов, которые с помощью операции drag-and-drop можно перетаскивать на рабочее поле.

Отдельно хотелось бы выделить CASE-систему Visual Paradigm, в которой частично реализован предлагаемый в данной статье подход. В Visual Paradigm жесты мышью подразделяются на три типа – жесты, порождающие объект, жесты, вызывающие команду и жесты, создающие связь между объектами. Жесты, порождающие объект и жесты, вызывающие команды задаются набором направлений (вверх, вниз, вправо, влево). Каждая диаграмма имеет отдельный ассоциированный с ней набор жестов, причём жесты имеют не все элементы палитры данной диаграммы, а только наиболее употребимые. Имеется контекстная справка, анимированно показывающая, как рисовать жест. Жесты иногда довольно сильно отличаются от создаваемых ими фигур. Жестов мышью в Visual Paradigm гораздо больше, чем в  утилитах, описанных ранее, но, как и в первых трех случаях, они жестко ``зашиты'' в код. В рамках же данной работы хотелось бы развить данную идею и предложить расширяемую технологию поддержки жестов мышью в CASE-средствах.

\subsection{Среда QReal}
В качестве CASE-пакета, в котором было решено внедрить и опробовать данный подход, была выбрана система QReal, разрабатываемая на кафедре системного программирования СПбГУ. 

Одной из важных особенностей архитектуры QReal является возможность расширения набора графических редакторов. Эта CASE-система состоит из ядра, реализующего общую для всех редакторов и элементов диаграмм функциональность, и подключаемых модулей, реализующих специфику конкретных редакторов. Эти подключаемые модули генерируются по метамоделям языков, которые редакторы реализуют (см. рис.~\ref{architecture}). Более подробно об архитектуре QReal и предлагаемом в этой системе подходе к  созданию новых визуальных редакторов можно прочитать в~\cite{qreal}. 

\begin{figure} [ht]
  \begin{center}
    \includegraphics[width=1\textwidth, bb=0 0 798 531]{01-architecture.png}
    \caption{Архитектура CASE-пакета QReal}
    \label{architecture}
  \end{center}
\end{figure}

В QReal для быстрой разработки новых редакторов имеется метаредактор с графическим редактором формы элементов диаграмм. Он позволяет создавать метамодели новых языков, описывая имеющиеся на диаграммах элементы и связи между ними. Также для каждого элемента метамодели можно нарисовать фигуру, задающую его визуальное представление на диаграммах. Созданную метамодель можно скомпилировать в подкючаемый модуль и подключить его к QReal прямо в процессе работы. Поскольку мы хотим иметь возможность добавлять поддержку  жестов мышью и в новые языки, то подобные особенности QReal должны быть учтены в разрабатываемом решении. 

\subsection{Обзор алгоритмов распознавания}
Задача компьютерного распознавания образов не нова --- различные варианты задач идентификации и классификации объектов решаются уже более сорока лет. За это время было разработано множество алгоритмов и подходов к решению самых разных задач распознавания, однако независимо от их класса и предметной области все подходы работают по следующей схеме: 
\begin{itemize}
  \item анализ и/или измерение объектов;
  \item выделение их характеристических признаков;
  \item классификация объектов в соответствии с полученными признаками.
\end{itemize}

\subsubsection{Этап измерения}
Основной задачей первого этапа является выделение траектории жеста. В таких задачах, как, например, распознавание движений по видеосигналу, этот этап может представлять наибольшую сложность, однако, применительно к решаемой задаче построение траектории сводится к отслеживанию перемещения координат курсора мыши, что не представляет сложностей в реализации. 

\subsubsection{Выделение признаков}
Большинство существующих алгоритмов распознавания работают с векторами характеристик объектов, которые позволяют абстрагироваться от несущественных для решаемой задачи признаков, например, таких, как пространственное положение и размеры распознаваемого объекта (см. например, обзор~\cite{handRecognition}). В нашем случае каждому жесту соответствует траектория движения курсора мыши --- список точек. Однако, использовать списки точек в качестве характеристических векторов не удается, так как при переносе или масштабировании жеста их координаты могут меняться довольно сильно. Мы будем рассматривать методы, предлагающие следующее решение проблемы: некоторым образом сопоставим каждому жесту строку символов (которую далее будем называть строкой-ключом) и будем сравнивать не списки точек траекторий, а соответствующие им ключи.

Наиболее очевидным подходом к построению ключа является отслеживание изменений ориентации сегментов ломаной, соответствующей жесту, относительно выбранной системы координат~\cite{chaosAlgorithm}. Участку жеста соответствует угол на плоскости, который попадает в один из диапазонов, а каждому из диапазонов углов ставится в соответствие символ в алфавите (см. рис.~\ref{chaos}). 

\begin{figure} [ht]
  \begin{center}
    \includegraphics[width=0.9\textwidth, bb=0 0 804 498]{02-chaos.png}
    \caption{Построение ключа по принадлежности направлению}
    \label{chaos}
  \end{center}
\end{figure}

Путь мыши при этом представляется как последовательность символов, соответствующих каждому из направлений. Недостаток этого алгоритма состоит в том, что даже небольшое дрожание руки, породившее короткий отрезок в неправильном направлении, добавит в ключ-строку новые символы, что может привести к ложному распознаванию жеста.

Другой алгоритм предлагает рассматривать не принадлежность направлению, а принадлежность прямоугольнику. Вокруг траектории законченного жеста описывается прямоугольник, каждая сторона которого делится на 8 частей (см. рис.~\ref{squares}). Каждому внутреннему прямоугольнику ставится в соответствие символ алфавита. Строка-ключ жеста будет состоять из символов, соответствующих прямоугольникам, по которым проходит трактория жеста. После удаления подряд идущих одинаковых символов из строки получаем окончательный ключ текущего жеста. 

\begin{figure} [ht]
  \begin{center}
    \includegraphics[width=0.8\textwidth, bb=0 0 544 390]{03-squares.png}
    \caption{Построение ключа по принадлежности прямоугольнику}
    \label{squares}
  \end{center}
\end{figure}

Эти алгоритмы хороши тем, что при их использовании не надо масштабировать жест. Подобным фигурам будут соответствовать одни и те же ключи.

Подряд идущие повторяющиеся символы можно не удалять, но тогда жест придется приводить к заранее определенному стандартному размеру. Но в этом случае при уменьшении некоторых ломаных может оказаться, что некоторые их части становятся слишком маленькими и
могут быть на этапе фильтрации приняты за шум.

\subsubsection{Классификация объектов}
Для различения объектов часто используются специальные математические модели, называемые классификаторами. Получая на вход вектор признаков, классификатор сообщает, к какому классу объектов принадлежит данный объект. 

Среди используемых подходов к классификации наибольшей популярностью в задачах распознавания пользуются такие математические модели, как искусственные нейронные сети~\cite{neuronet1, neuronet2, neuronet3}, скрытые марковские модели~\cite{hmm1, hmm2, hmm3}, а также классификаторы, получаемые обучением с помощью, например, метода опорных векторов~\cite{svm1, svm2} или алгоритмов AdaBoost/FloatBoost~\cite{boosting1, boosting2}. Принцип работы у всех этих классификаторов примерно одинаковый --- вначале осуществляется фаза обучения, на которой классификатору на вход подается набор эталонных объектов, соответствующих каждому классу. В рабочем режиме обученный классификатор сопоставляет входные вектора признаков классу, соответствующему данным объектам.

Наличие этапа обучения для нашей задачи недопустимо, поскольку в процессе метамоделирования новые сущности могут появляться довольно часто, а обучение требует наличия большой базы примеров (например, набора типичных траекторий для каждого жеста). Такую базу невозможно создать в короткие сроки при быстрой разработке предметно-ориентированного языка. Данное ограничение является довольно серьезным и, к сожалению, не позволяет нам использовать данный вид классификаторов для решения поставленной задачи.

Другим часто используемым в распознавании образов подходом к классификации объектов является так называемая задача поиска ближайшего соседа~\cite{nns1, nns2}, заключающийся в отыскании среди множества элементов, расположенных в некоем метрическом пространстве (в общем случае, многомерном), элементов, близких к заданному, согласно некоторой функции близости. В случае представления траекторий строками из некоторого алфавита в качестве функции близости можно взять расстояние Левенштейна, которое определяется как минимальное количество операций вставки одного символа, удаления одного символа и замены одного символа на другой для превращения одной строки в другую~\cite{levenshtein}. Однако, расстояние Левенштейна обладает следующим недостатком: расстояния между совершенно разными короткими строками оказываются небольшими, а расстояния между похожими длинными словами оказываются значительными. Поэтому обычно используется не само расстояние, а соотношение 

\begin{equation}
\label{levenshtein}
d_{normalized}(s1,s2) = \frac{d(s1,s2)}{min(s1,s2)},
\end{equation}

где d(s1,s2) -- расстояние Левенштейна между строками s1 и s2, а min(s1,s2) -- минимум длин этих строк.

\subsubsection{Алгоритм распознавания жестов без генерации строки-ключа}
\label{qtAlgorithm}
При создании QReal использовался инструментарий Qt\footnote{http://qt.nokia.com/}, разработчиками которого предложен свой алгоритм распознавания жестов мышью, не требующий в процессе работы построения строки-ключа и основанный на анализе изменения направлений участков жеста~\cite{qtGestures}. Рассмотрим шаги алгоритма.
\begin{enumerate}
  \item Фильтрация пути мыши.
  \item Сопоставление объекта из списка. Предполагается, что объект в этом алгоритме --- это ломаная.
  \begin{enumerate}
    \item Приближение направлениями. На этом этапе каждый сегмент ломаной приближается одним из заранее определенных базовых направлений. Как правило, их четыре --- вверх, вниз, вправо, влево. Для большей точности количество базовых направлений можно увеличить, при этом удобно брать число, кратное четырем, чтобы четыре базовых направления оставались неизменными, и каждое было биссектрисой двух соседних. При увеличении числа направлений к эталонным жестам можно добавлять сложные многоугольники, стороны которых не обязательно параллельны осям координат, которые было бы невозможно распознать в случае использования только четырех направлений.
    \item Упрощение списка направлений, заключающееся в том, чтобы найти подряд идущие сонаправленные вектора и объединить их в один вектор, просуммировав длину.
    \item Сопоставление и удаление. Эта часть алгоритма является, пожалуй, наиболее сложной, так как, несмотря на фильтрацию, останутся мелкие сбои вдоль длинных отрезков. На этом шаге полученному списку направлений сопоставляется эталонный жест команды. Если соответствующий эталонный жест не найден, мы удаляем кратчайший отрезок и повторяем попытку. Алгоритм заканчивается, если удалось получить команду, или большая часть первоначального списка направлений была удалена.
  \end{enumerate}
\end{enumerate}

Недостаток этого алгоритма состоит в том, что изменение оставшихся отрезков после удаления самого короткого довольно нетривиально. Чтобы путь не потерял связность, удалить отрезок, не изменив концы соседних с ним, невозможно. Чтобы отрезки сохранили свое направление, придется менять не только соседние. Например, на рис.~\ref{qt} слева показана часть пути мыши. После удаления самого короткого отрезка с номером 2, переносим отрезок номер 3, тем самым меняя координаты начала отрезка номер 4. Путь преобразуется в траекторию, приведенную на рис.~\ref{qt} справа. Стоит заметить, что при увеличении числа направлений перестраивать путь будет все сложнее. 

\begin{figure} [ht]
  \begin{center}
    \includegraphics[width=0.8\textwidth, bb=0 0 500 200]{04-qt.png}
    \caption{Объединение участков пути}
    \label{qt}
  \end{center}
\end{figure}

\section{Предлагаемый подход}
\label{rectAlgorithm}
Исходя из рассмотренных алгоритмов распознавания, а также в соответствии со спецификой задачи, был выбран подход, основанный на формировании строки-ключа алгоритмом определения принадлежности прямоугольнику и использовании в качестве классификатора модифицированной функции Левенштейна~(\ref{levenshtein}). Однако, для классификации жестов требуется набор эталонов --- объектов, с которыми сравнивается входной набор признаков при поиске ближайшего соседа. В нашем случае эталонные вектора признаков будут строиться по так называемым ``идеальным жестам'' --- жестам, генерируемым на основе графического представления элементов. 

Для каждого объекта в QReal есть графическое представление, которое задается с помощью текстового языка на основе XML (подробнее см. в~\cite{qreal}). Описание элемента представляет собой набор отрезков, каждый из которых определяется координатами начала и конца, и набор окружностей, которые определяются координатами центра и диаметром (для того, чтобы работать только с точками и отрезками, окружность при равномерном движении мыши можно приближать правильным многоугольником). Таким образом, для каждого объекта можно выделить набор вершин (концы всех отрезков и точки на окружности) и ребер (отрезки) и построить по ним граф, соответствующий объекту. Построение ``идеального жеста'' основано на понятии эйлерова пути графа --- пути, проходящего по всем ребрам графа, причем по каждому из них только по одному разу. Если в полученном графе объекта эйлеров путь не существует, добавим несколько ребер так, чтобы эйлеров путь существовал. Добавлять будем ребра, связывающие два подграфа, в которых уже существуют эйлеровы пути.

Полученный эйлеров путь и будем считать ``идеальным жестом'' для данного объекта. 

Общая схема процесса распознавания мышиного жеста такова.

\begin{itemize}
  \item CASE-система получает сигналы о том, что пользователь зажал правую кнопку мыши и перемещает курсор, и сохраняет координаты положения курсора через равные промежутки времени. Жест считается завершенным, когда пользователь отпускает кнопку мыши.
  \item Осуществляется сглаживание полученной траектории. Этот шаг необходим, так как различное оборудование дает разную точность при получении позиции курсора. Кроме того, если учитывать все дрожания руки, придется усложнять следующий шаг --- сопоставление объекта: каждому объекту будет соответствовать слишком много разных вариантов пути мыши.
  \item Списку точек сопоставляется строка в соответствии с алгоритмом, отраженным на рис.~\ref{squares}.
  \item С помощью модифицированного алгоритма Левенштейна находится идеальный ключ, расстояние $d_{normalized}$~(\ref{levenshtein}) между которым и сгенерированным по нарисованному жесту наименьшее. Если ключ достаточно близок к идеальному, на диаграмме создается объект, соответствующий этому ключу.
\end{itemize}

\subsection{Описание функциональности}
В предложенной реализации список ``идеальных жестов'' создается на основе графических представлений элементов на этапе генерации соответствующего визуального редактора.

Далее, чтобы создать определенный элемент, пользователь CASE-системы зажимает правую кнопку мыши и делает соответствующий жест. Для того, чтобы пользователь мог контролировать процесс рисования, система показывает получающийся путь (см. рис.~\ref{drawing}, рисуемый жест заведомо укрупнен).

\begin{figure} [ht]
  \begin{center}
    \includegraphics[width=0.8\textwidth, bb=0 0 800 600]{05-drawing.png}
    \caption{Рисование жеста для элемента Decision Node диаграммы активностей UML}
    \label{drawing}
  \end{center}
\end{figure}

После того, как пользователь отпускает правую кнопку мыши, жест считается завершенным и QReal строит ключ-строку в соответствии с алгоритмом, отраженным на рис.~\ref{squares}. По тому, какая диаграмма была активна в момент рисования жеста, определяется нужный графический редактор, у него запрашивается список ``идеальных жестов'' всех описанных в нем элементов и считается расстояние Левенштейна между каждым из них и нарисованным. Тот элемент, расстояние до которого будет минимальным (но в то же время достаточно небольшим, чтобы исключить ложно-позитивные срабатывания для совсем непохожих жестов), создается в центре изображенного пользователем жеста, а сама ломаная исчезает. 

Возникает проблема похожести жестов: ``идеальный жест'' генерируется по описанию графического представления объекта, и если графически объекты похожи, то и жесты для них будут похожи. В пределах одного редактора малоразличимые ``идеальные жесты'' дается возможность редактировать вручную: например, вводится операция вращения, и некоторые жесты предлагается рисовать по часовой стрелке, а некоторые --- против. В данный момент решение о вращении ``идеального жеста'' принимает разработчик визуального языка при описании этого элемента в метамодели. 

Однако, одной только операции вращения иногда оказывается мало, так как внутри одного языка может быть довольно много визуально похожих элементов. В таком случае после рисования жеста CASE-система предлагает выбрать нужный элемент из выпадающего меню, появляющегося после завершения жеста. Элементов в таком меню будет значительно меньше, чем во всей палитре редактора.

Данный подход был также расширен и на создание ассоциаций на диаграммах. Так как у связей между объектами графическое представление как таковое отсутствует (стиль начертания линий, а также стиль заливки и форма стрелок для наших целей подходят плохо), логично 
предположить, что жестом, порождающим такую ассоциацию, будет кривая, соединяющая два нужных элемента. Если QReal замечает жест, начинающийся и заканчивающийся на уже существующих на диаграмме объектах, то через API доступа к плагинам получается список 
ассоциаций, допустимых между объектами данных типов, и отображается в выпадающем меню, аналогично рассмотренному выше случаю создания элементов. После выбора одного из пунктов меню между данными объектами создается соответствующая связь (отметим, что если в данном списке связей находится всего одна ассоциация, она создается сразу же после завершения жеста).

\subsection{Апробация}

Результативность предлагаемого алгоритма распознавания была измерена на элементах редактора диаграммы активностей UML 2. Для этого был реализован специальный инструмент, который работал по следующему принципу:
\begin{itemize}
  \item Загружается набор идеальных жестов из .xml-файла. Идеальные жесты генерировались автоматически при компиляции соответствующего редактора в QReal.
  \item Пользователь выбирает один из идеальных жестов в списке и начинает рисовать жесты, соответствующие выбранному.
  \item Пути нарисованных жестов сохраняются в .xml-файл. Тестовый инструмент умеет загружать существующие пути из этого файла и дополнять их вновь нарисованными, таким образом, можно обеспечить параллельность формирования базы жестов.
  \item Когда формирование базы жестов завершено, на каждом из сохранённых жестов запускаются тестируемые алгоритмы. Сравнение проводилось между алгоритмом, описанным в~\ref{qtAlgorithm} и предлагаемым нами алгоритмом.
\end{itemize}

Результаты тестирования приведены в~\ref{experimentsTable}. Для каждого элемента было нарисовано 100 жестов.

\begin{table} [ht]
\begin{center}
  \label{experimentsTable}
  \fontsize{7}{18}
  \selectfont
  \begin{tabular} {| c | c || c | c | c || c | c | c || c | c | c ||}
    \hline
    \multirow{2}{*}{№} & \multirow{2}{*}{Идеальный жест}                           & \multicolumn{3}{c||}{rect} & \multicolumn{3}{c||}{qt}          & \multicolumn{3}{c||}{dir}  \\
    \cline{3-11}
      &                                                                               & +       & ?      & -       & +          & ?         & -        & +       & ?         & -     \\ \hline     
    1 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 109 68]{gesture1.png}}     & 26\%    & 74\%   & 0\%     & 11\%       & 1\%       & 88\%     & 21\%    & 70\%      & 9\%   \\ \hline
    2 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 49 60]{gesture2.png}}      & 94\%    & 1\%    & 5\%     & 3\%        & 0\%       & 97\%     & 12\%    & 81\%      & 7\%   \\ \hline
    3 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 67 64]{gesture3.png}}      & 92\%    & 1\%    & 7\%     & 100\%      & 0\%       & 0\%      & 63\%    & 36\%      & 1\%   \\ \hline
    4 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 105 56]{gesture4.png}}     & 61\%    & 38\%   & 1\%     & 19\%       & 15\%      & 66\%     & 58\%    & 20\%      & 22\%  \\ \hline
    5 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 106 55]{gesture5.png}}     & 98\%    & 2\%    & 0\%     & 57\%       & 0\%       & 43\%     & 67\%    & 7\%       & 26\%  \\ \hline
    6 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 63 62]{gesture6.png}}      & 96\%    & 1\%    & 3\%     & 0\%        & 15\%      & 85\%     & 6\%     & 87\%      & 7\%   \\ \hline
    7 &  \scalebox{0.45}{\includegraphics[scale=0.35, bb=0 0 112 110]{gesture7.png}}  & 69\%    & 30\%   & 1\%     & 95\%       & 0\%       & 5\%      & 44\%    & 45\%      & 11\%  \\ \hline
    8 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 52 47]{gesture8.png}}      & 98\%    & 2\%    & 0\%     & 25\%       & 3\%       & 72\%     & 55\%    & 42\%      & 3\%   \\ \hline
    9 &  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 46 46]{gesture9.png}}      & 84\%    & 0\%    & 16\%    & 92\%       & 0\%       & 8\%      & 76\%    & 22\%      & 2\%   \\ \hline
    10&  \scalebox{0.5}{\includegraphics[scale=0.5, bb=0 0 103 64]{gesture10.png}}    & 93\%    & 5\%    & 2\%     & 0\%        & 63\%      & 37\%     & 34\%    & 50\%      & 16\%  \\ \hline
  \end{tabular}
  \caption{Результаты сравнения алгоритмов}
\end{center}
\end{table}

Условные обозначения: \\
``rect'' --- алгоритм с выделением признаков методом прямоугольников, предлагаемый в данной статье (см. \ref{rectAlgorithm}).\\
``qt'' --- алгоритм, рассмотренный в \ref{qtAlgorithm}. \\
``dir'' --- алгоритм, основанный на отслеживании изменения направлений (см.~\ref{chaos}). \\
``+'' --- жест распознан. \\
``-'' --- жест не распознан. \\
``?'' --- ложно-позитивное распознавание. \\

Элементы 4 и 5 в таблице имеют одинаковое графическое представление, поэтому для одного из них при генерации ``идеальных жестов'' была применена операция вращения. Жесты для элемента 4 рисовались по часовой стрелке, а для элемента 5 --- против часовой.

Как видно из таблицы, предлагаемый нами алгоритм в большинстве случаев работает лучше, чем два остальных рассмотренных алгоритма. Алгоритм \textit{qt} показывает низкое качество распознавания фигур, содержащих в себе наклонные линии, потому что они приближаются горизонтальными и вертикальными. Фигуры, которые наклонных линий в себе практически не содержат, распознаются этим алгоритмом практически идеально. Алгоритм \textit{dir} корректно распознал несколько больше жестов, чем алгоритм \textit{qt}, однако, высокий процент ложных срабатываний делает его малоприменимым на практике. Связано это с тем, что для этого алгоритма требуется дополнительная фильтрация для учёта похожих направлений: идеальная прямая породит ключ, состоящий из одного символа, а та же прямая с шумом, вызванным, например, дрожанием руки, породит сложный и длинный ключ, сильно отличающийся от идеального. Таким образом, при реализации приходится выбирать между большим количеством ложных срабатываний и приемлемым количеством срабатываний правильных, или большим процентом жестов, не распознанных вовсе.

Алгоритм \textit{rect} таких проблем не имеет, однако, для некоторых элементов так же недопустимо высок процент ложных срабатываний. Например, жест 1 часто путался с жестом 10, алгоритмом \textit{qt} же он практически не распознается. 

\subsection{Выводы}
Пробная эксплуатация этого алгоритма в системе показала, что данный подход в предложенном варианте ограниченно применим на практике. Так, создание ассоциаций с помощью жестов действительно показало себя удобным и реально повышающим производительность труда проектировщика. Однако, для достаточно большого набора фигур в палитре точность распознавания реализованного алгоритма (и рассматриваемых аналогов) оказывается недостаточной. Связано это, по нашему мнению, с тем, что для CASE-систем существует некий порог приемлемой точности распознавания жестов. Если алгоритм обеспечивает точность распознавания выше этого порога, то использование жестов мышью оказывается более удобным и эффективным, чем перетаскивание элементов с палитры, если нет, то пользователю придется потратить больше усилий на рисование фигуры. Данная проблема усугубляется тем, что в CASE-системах требуется распознавать достаточно много (порядка десятков) достаточно похожих жестов, и если для простых приложений, где требуется распознавать единицы жестов, данные алгоритмы могут обеспечить достаточное качество распознавания, в CASE-системах этого добиться не удаётся.

Однако, в случае использования CASE-средств на компьютерах с сенсорными экранами или на электронных досках данный подход кажется нам имеющим право на практическое применение, потому что пером на экране рисовать проще, чем мышью, а перетаскивать элементы сложнее. Кроме того, если набор элементов, для которых будут задаваться жесты, ограничить наиболее часто используемыми и не пытаться распространять подход на все присутствующие в палитре элементы, точность распознавания можно повысить до приемлемой.

\section{Заключение}
Подход, предлагаемый в этой статье, был реализован и внедрён в CASE-систему QReal. На основе проведённых экспериментов были сделаны выводы о применимости описанного в статье решения в расширяемых CASE-системах.
\begin{itemize}
  \item Использование хорошо зарекомендовавших себя в других областях подходов к классификации объектов, основанных на обучении, оказалось затруднительно в системах, где набор распознаваемых объектов может меняться динамически.
  \item Используемый нами классификатор, не использующий обучение, показал недостаточную для практического использования точность распознавания. Однако, при определённых ограничениях рассматриваемые в статье методы обеспечивают приемлемое качество распознавания: во-первых, можно сократить количество классов  распознаваемых объектов, во-вторых, можно использовать более точные, чем мышь, механизмы рисования жеста, например, сенсорные экраны. При подобных ограничениях использование жестов мышью в качестве инструмента для создания новых элементов показало себя достаточно удобным.
\end{itemize}

\pagebreak

\begin{thebibliography}{9001}
  \bibitem{levenshtein} В.И. Левенштейн. Двоичные коды с исправлением выпадений, вставок и замещений символов // Доклады Академий Наук СССР, 1965. 163.4:845-848
  \bibitem{qreal} А.Н. Терехов, Т.А. Брыксин, Ю.В. Литвинов и др., Архитектура среды визуального моделирования QReal. // Системное 
программирование. Вып. 4: Сб. статей / Под ред. А.Н.Терехова, Д.Ю.Булычева. --- СПб.: 2009, с. 171-196
  \bibitem{svm1} Aizerman, M., Braverman, E., Rozonoer, L., Theoretical foundations of the potential function method in pattern recognition learning, 
Automation and Remote Control 25, 1964, pp. 821–837
  \bibitem{neuronet1} Bishop, C.M., Neural Networks for Pattern Recognition, Oxford: Oxford University Press, 1995  
  \bibitem{chaosAlgorithm} Brun, D., Mouse gesture recognition // ByteArray.org Actionscript 3 Experiments. URL: http://www.bytearray.org/?p=91 
  \bibitem{svm2} Catanzaro, B., Sundaram N., Keutzer K., Fast Support Vector Machine Training and Classification on Graphics Processors, International 
Conference on Machine Learning, 2008
  \bibitem{neuronet3} Faaborg, A.J., Using Neural Networks to Create an Adaptive Character Recognition System, Cornell University, Ithaca, NY, 2002
  \bibitem{flyGesture} FlyGesture, URL: http://flyingmeat.com/flygesture/
  \bibitem{boosting1} Freund, Y., Schapire, R.E., A Short Introduction to Boosting, AT\&T Labs Research, 1999
  \bibitem{gMote} gMote, URL: http://www.handform.net/gmote.php
  \bibitem{boosting2} Li, S.Z., Zhang, Z., FloatBoost Learning and Statistical Face Detection, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004
  \bibitem{nns1} Potamias, M., Athitsos, V. , Nearest Neighbor Search Methods for Handshape Recognition, PETRA, 2008
  \bibitem{hmm1} Rabiner, Lawrence R., A tutorial on hidden Markov models and selected applications in speech recognition, Proceedings of the IEEE, 1989, pp. 257-286
  \bibitem{neuronet2} Ripley, B.D., Pattern Recognition and Neural Networks, Cambridge University Press, 1996
  \bibitem{hmm2} Starner, T., Pentland, A., Visual Recognition of American Sign Language Using Hidden Markov Models, MIT, 1995
  \bibitem{strokeIt} StrokeIt, URL: http://www.tcbmi.com/strokeit/  
  \bibitem{nns2} Shakhnarovish, Darrell, and Indyk, Nearest-Neighbor Methods in Learning and Vision, MIT Press, 2005
  \bibitem{qtGestures} Thelin, J., Recognizing mouse gestures, Qt online reference documentation, URL: http://doc.trolltech.com/qq/qq18-mousegestures.html 
  \bibitem{hmm3} Vlontzos, J.A., Kung, S.Y., Hidden Markov models for character recognition, IEEE Transactions on Image Processing, 1992
  \bibitem{xstroke} xstroke, URL: http://freshmeat.net/projects/xstroke/
  \bibitem{handRecognition} Zabulis, X., Baltzakis, H., Argyros, A. Vision-based hand gesture recognition for human-computer interaction, URL: http://www.ics.forth.gr/indigo/pdf/chapter\_gestures\_submitted.pdf
\end{thebibliography}
  

\end{document}